{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0e0cf3-70f1-4626-85da-2fa84148a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9896752a-d8a4-4a43-a110-2f2219d909c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for Missing Values\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5087f76d-7d28-48a2-a1f5-89b19a07c310",
   "metadata": {},
   "source": [
    "Missing values: Verified and none were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56e7104-2f52-430a-b54b-a8511c48af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79005d81-eae7-4f41-b59d-bbb361e2df45",
   "metadata": {},
   "source": [
    "Feature Scaling: SVM, k-NN, and Logistic Regression are sensitive to feature scale. Therefore, standardization is necessary to normalize all features to the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e16ad845-fd80-45ef-a24b-bb46acbc2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Algorithm Implementation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f6241d7-d31f-412f-8288-2004f2cc9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e69a7aa-5b8d-4967-8f8b-98ae00b0a494",
   "metadata": {},
   "source": [
    "Logistic Regression estimates the probability of class membership via a sigmoid function. It's best suited for binary classification tasks such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "849ea457-507d-435d-8dc7-c76fcfd39272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9edd852f-fe79-4d5b-bdd3-caeb21c9ffff",
   "metadata": {},
   "source": [
    "Decision Trees divide data by feature thresholds to make a decision. They work well with both categorical and numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1255bf53-7647-49f4-838b-b178d9c65d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6b69ee9-00c6-461e-a914-7a03909c78e5",
   "metadata": {},
   "source": [
    "Mitigates overfitting by averaging the predictions of multiple trees. Excellent for high-dimensional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98549b59-6af2-447c-92ac-0558c73d4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45e9ae7c-97e3-4715-9d9e-6f9b7a6a9607",
   "metadata": {},
   "source": [
    "SVM determines the best hyperplane that maximally separates classes. Works well in high-dimensional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48104d3c-58a2-465f-aec3-85cc3f19780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b175c6a3-56c3-4c70-a2c5-50f83870c044",
   "metadata": {},
   "source": [
    "k-NN gives a class by majority class among k-nearest samples. Effective and simple, but computationally costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d6bb701-121f-4d09-9efb-a12933a95926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9737\n",
      "Decision Tree: 0.9474\n",
      "Random Forest: 0.9649\n",
      "SVM: 0.9737\n",
      "k-NN: 0.9474\n"
     ]
    }
   ],
   "source": [
    "#Model Comparison\n",
    "results = {\n",
    "    \"Logistic Regression\": lr_acc,\n",
    "    \"Decision Tree\": dt_acc,\n",
    "    \"Random Forest\": rf_acc,\n",
    "    \"SVM\": svm_acc,\n",
    "    \"k-NN\": knn_acc\n",
    "}\n",
    "\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63cc597d-d55f-4670-a363-195b2727f9ea",
   "metadata": {},
   "source": [
    "Best and Worst Performing Algorithms:\n",
    "Best: SVM (Highest accuracy)\n",
    "\n",
    "Worst: Decision Tree (Lower accuracy due to potential overfitting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
