{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd19815-9bd0-49c4-aeb4-5bb41f26c634",
   "metadata": {},
   "source": [
    "# 1. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c4ab0f1-34e3-44ae-901c-02ed2069096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "california_housing = fetch_california_housing()\n",
    "data = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "data['MedHouseVal'] = california_housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb63a91d-f89e-4873-8f12-92094df62b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5898fd21-9a6e-4e86-91be-be958719d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Split into features and target\n",
    "X = data.drop('MedHouseVal', axis=1)\n",
    "y = data['MedHouseVal']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c3486-0b4f-455b-b1e3-8aac5b54d560",
   "metadata": {},
   "source": [
    "1. No missing values handling needed: The dataset is already cleaned and doesn't contain missing values.\n",
    "\n",
    "2. Feature scaling: Standardization (StandardScaler) was applied because:\n",
    "\n",
    "- Many algorithms (like SVR, Gradient Boosting) perform better when features are on similar scales\n",
    "\n",
    "- Features in this dataset have different units and ranges (e.g., 'AveRooms' vs 'Latitude')\n",
    "\n",
    "- Helps algorithms converge faster and prevents features with larger scales from dominating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc565f-dc52-4389-9404-4e894f8815cb",
   "metadata": {},
   "source": [
    "# 2. Regression Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1545c47d-7f08-4204-9711-7e0a0bb4e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Evaluation Function\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {'MSE': mse, 'MAE': mae, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1694a5c-992f-465c-a85b-f9333470288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "{'MSE': 0.555891598695244, 'MAE': 0.5332001304956564, 'R2': 0.5757877060324511}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "result = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d586caca-9b51-41b8-9d3c-7a3836141d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R²: 0.5758\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr_results = evaluate_model(lr, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(f\"Linear Regression R²: {lr_results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e81fe276-bc22-4249-bc8a-1e58431c9530",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Linear Regression models the relationship between features and target by fitting a linear equation. It assumes a linear relationship between input variables and the single output variable.\n",
    "\n",
    "Suitability:\n",
    "Good baseline model for housing price prediction as some relationships between features and price may be linear (e.g., more rooms → higher price). Simple and interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "257ac425-ba81-4c49-96d4-c6f6dd61f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree R²: 0.6230\n"
     ]
    }
   ],
   "source": [
    "#  Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt_results = evaluate_model(dt, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(f\"Decision Tree R²: {dt_results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cea5d69-82c9-493f-a741-1792d4ac27d4",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Decision trees split the data into subsets based on feature values, creating a tree-like model of decisions. Predictions are made by traversing the tree from root to leaf.\n",
    "\n",
    "Suitability:\n",
    "Can capture non-linear relationships in housing data. Works well with mixed feature types. However, prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dd9a24e-2fcb-4594-a1bc-daf0bc1af4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R²: 0.8053\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_results = evaluate_model(rf, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(f\"Random Forest R²: {rf_results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9deb4bb4-6c62-4ff4-ad51-203b4efc8c92",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "An ensemble method that builds multiple decision trees and averages their predictions. Uses bagging (bootstrap aggregating) to reduce variance.\n",
    "\n",
    "Suitability:\n",
    "Often performs well on housing datasets by reducing overfitting compared to single decision trees. Can capture complex relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd0cb9af-d6fa-4c9d-86be-5e271ead6415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R²: 0.7756\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb_results = evaluate_model(gb, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(f\"Gradient Boosting R²: {gb_results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "430b1fdc-0c66-40f6-90d0-e642abd68c64",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Builds trees sequentially where each tree corrects errors of the previous one. Uses boosting to combine weak learners into a strong learner.\n",
    "\n",
    "Suitability:\n",
    "Often provides excellent results for housing price prediction by focusing on difficult cases. Handles non-linear relationships well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cecadcc-f5b8-46fd-be26-cbdfd79bc93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR R²: 0.7276\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor (SVR)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr_results = evaluate_model(svr, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(f\"SVR R²: {svr_results['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf2ef313-0184-4bf9-8e8b-13a253c85259",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Finds a hyperplane in high-dimensional space that best fits the data while allowing some tolerance (ε-insensitive tube). Uses kernel trick for non-linear relationships.\n",
    "\n",
    "Suitability:\n",
    "Can model complex relationships in housing data, especially with non-linear kernels. Works well with scaled features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd369a0-9f84-4851-99c2-26b6d8649aa1",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035ce407-ce7e-4ba0-86f2-e6e531e7356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MSE       MAE        R2\n",
      "Linear Regression  0.555892  0.533200  0.575788\n",
      "Decision Tree      0.493969  0.453904  0.623042\n",
      "Random Forest      0.255170  0.327425  0.805275\n",
      "Gradient Boosting  0.293999  0.371650  0.775643\n",
      "SVR                0.357004  0.398599  0.727563\n"
     ]
    }
   ],
   "source": [
    "# Results Comparison\n",
    "results = {\n",
    "    'Linear Regression': lr_results,\n",
    "    'Decision Tree': dt_results,\n",
    "    'Random Forest': rf_results,\n",
    "    'Gradient Boosting': gb_results,\n",
    "    'SVR': svr_results\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2affa-0f8d-405b-96ba-6253f9bdf8ba",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e181b6b-c161-41ef-b776-6af85ca08def",
   "metadata": {},
   "source": [
    "### Best-performing algorithm:\n",
    "\n",
    "Gradient Boosting Regressor or Random Forest Regressor\n",
    "\n",
    "These ensemble methods perform well because:\n",
    "\n",
    "- They can capture complex, non-linear relationships between features and price\n",
    "\n",
    "- Are robust to outliers and feature scales\n",
    "\n",
    "- Reduce overfitting compared to single decision trees\n",
    "\n",
    "- Generally show high R² scores and low MSE/MAE\n",
    "\n",
    "### Worst-performing algorithm:\n",
    "\n",
    "Linear Regression or SVR\n",
    "\n",
    "Reasons:\n",
    "\n",
    "- Linear Regression may be too simplistic for the complex relationships in housing data\n",
    "\n",
    "- SVR can perform poorly if not properly tuned (kernel selection, C, epsilon parameters)\n",
    "\n",
    "- Both may struggle with interactions between features that tree-based methods capture naturally\n",
    "\n",
    "### Key Observations:\n",
    "1. Ensemble methods (Random Forest, Gradient Boosting) generally outperform simpler models\n",
    "\n",
    "2. Decision Trees may overfit without proper pruning\n",
    "\n",
    "3. Performance can often be improved with hyperparameter tuning for each algorithm\n",
    "\n",
    "4. The choice between best models may depend on computational resources and need for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55b727-ca7e-4b03-8973-762c73d06fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
